{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import datetime\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_file_with_wildcard(pattern):\n",
    "    \"\"\"Find file with wildcard pattern, raise error if no match or multiple matches.\"\"\"\n",
    "    # Use glob to find matching files\n",
    "    matching_files = glob.glob(pattern)\n",
    "    \n",
    "    # Check if no file was found\n",
    "    if len(matching_files) == 0:\n",
    "        raise FileNotFoundError(f\"No files found matching pattern: {pattern}\")\n",
    "    \n",
    "    # Check if more than one file was found\n",
    "    if len(matching_files) > 1:\n",
    "        raise ValueError(f\"Multiple files found matching pattern: {pattern}\")\n",
    "    \n",
    "    # Return the matched file path\n",
    "    return matching_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scopes for accessing Google Drive\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "MEMORY_FILE = 'processed_files.json'\n",
    "CREDENTIALS_FILE_WILDCARDED = './.credentials/client_secret*.json'\n",
    "CREDENTIALS_FILE = find_file_with_wildcard(CREDENTIALS_FILE_WILDCARDED)\n",
    "TOKEN_FILE = './.credentials/token.json'\n",
    "SERVER_FOLDER = \"server_files\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drive helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate_google_drive():\n",
    "    \"\"\"Authenticate with Google Drive and return the service object.\"\"\"\n",
    "    creds = None\n",
    "    # Check if token.json exists (token storage for authenticated user)\n",
    "    if os.path.exists(TOKEN_FILE):\n",
    "        print(\"Loading credentials from token.json\")\n",
    "        creds = Credentials.from_authorized_user_file(TOKEN_FILE, SCOPES)\n",
    "    \n",
    "    # Authenticate if credentials are not valid or do not exist\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            print(\"Refreshing expired credentials\")\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            print(\"Authenticating with Google Drive\")\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(CREDENTIALS_FILE, SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save credentials for the next run\n",
    "        with open(TOKEN_FILE, 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    \n",
    "    # Build the Drive API service\n",
    "    return build('drive', 'v3', credentials=creds)\n",
    "\n",
    "def get_items_by_name(service, name, is_folder=False, is_root=False):\n",
    "    \"\"\"Get a list of items by name, including their modified time, sorted by modified time.\"\"\"\n",
    "    try:\n",
    "        q = f\"name = '{name}'\"\n",
    "        if is_folder:\n",
    "            q += \" and mimeType = 'application/vnd.google-apps.folder'\"\n",
    "        else:\n",
    "            q += \" and mimeType != 'application/vnd.google-apps.folder'\"\n",
    "        if is_root:\n",
    "            q += \" and 'root' in parents\"\n",
    "\n",
    "        results = service.files().list(\n",
    "            q=q,\n",
    "            fields=\"nextPageToken, files(id, name, mimeType, modifiedTime, parents)\",\n",
    "            orderBy=\"modifiedTime desc\"\n",
    "        ).execute()\n",
    "        return results.get('files', [])\n",
    "    except HttpError as error:\n",
    "        print(f\"An error occurred: {error}\")\n",
    "        return []\n",
    "\n",
    "def move_file_to_folder(service, file_id, folder_id):\n",
    "    \"\"\"Move a file to a specific folder in Google Drive.\"\"\"\n",
    "    try:\n",
    "        # Retrieve the current parents\n",
    "        file = service.files().get(fileId=file_id, fields='parents').execute()\n",
    "        previous_parents = \",\".join(file.get('parents', []))\n",
    "\n",
    "        # Move the file to the new folder\n",
    "        service.files().update(\n",
    "            fileId=file_id,\n",
    "            addParents=folder_id,\n",
    "            removeParents=previous_parents,\n",
    "            fields='id, parents'\n",
    "        ).execute()\n",
    "        print(f\"File {file_id} has been moved to folder {folder_id}.\")\n",
    "    except HttpError as error:\n",
    "        print(f\"An error occurred while moving the file: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drive variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading credentials from token.json\n",
      "Refreshing expired credentials\n"
     ]
    }
   ],
   "source": [
    "SERVICE = authenticate_google_drive()\n",
    "FLASCHARD_FILE_ARCHIVE_FOLDER = \"_Pleco\"\n",
    "FLASCHARD_FILE_ARCHIVE_FOLDER_ID = get_items_by_name(SERVICE, FLASCHARD_FILE_ARCHIVE_FOLDER, is_folder=True, is_root=True)[0]['id']\n",
    "FLASHCARD_FILE_NAME = \"pleco_flashcards.xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## anki connect variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnkiConnect API endpoint\n",
    "ANKI_CONNECT_URL = \"http://localhost:8765\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## anki connect methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_card_info(deck_name):\n",
    "    \"\"\"Retrieve detailed card information from a specified deck.\"\"\"\n",
    "    find_payload = {\n",
    "        \"action\": \"findCards\",\n",
    "        \"version\": 6,\n",
    "        \"params\": {\n",
    "            \"query\": f'deck:\"{deck_name}\"'  # Query for cards only in the specified deck\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(ANKI_CONNECT_URL, json=find_payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        find_result = response.json()\n",
    "        if 'result' in find_result and find_result['result']:\n",
    "            card_ids = find_result['result']\n",
    "            info_payload = {\n",
    "                \"action\": \"cardsInfo\",\n",
    "                \"version\": 6,\n",
    "                \"params\": {\n",
    "                    \"cards\": card_ids  # Pass the list of card IDs\n",
    "                }\n",
    "            }\n",
    "\n",
    "            info_response = requests.post(ANKI_CONNECT_URL, json=info_payload)\n",
    "\n",
    "            if info_response.status_code == 200:\n",
    "                info_result = info_response.json()\n",
    "                if 'result' in info_result and info_result['result']:\n",
    "                    return info_result['result']\n",
    "                else:\n",
    "                    raise ConnectionError(f\"Error retrieving card information: {info_result.get('error')}\")\n",
    "            else:\n",
    "                raise ConnectionError(\"Failed to connect to AnkiConnect for card information.\")\n",
    "        else:\n",
    "            raise ValueError(f\"No cards found or error: {find_result.get('error')}\")\n",
    "    else:\n",
    "        raise ConnectionError(\"Failed to connect to AnkiConnect for finding cards.\")\n",
    "\n",
    "def sync_anki():\n",
    "    sync_payload = {\n",
    "        \"action\": \"sync\",\n",
    "        \"version\": 6\n",
    "    }\n",
    "\n",
    "    sync_response = requests.post(ANKI_CONNECT_URL, json=sync_payload)\n",
    "\n",
    "    if sync_response.status_code == 200:\n",
    "        sync_result = sync_response.json()\n",
    "        if sync_result.get('error'):\n",
    "            raise ConnectionError(f\"Error syncing Anki: {sync_result['error']}\")\n",
    "        else:\n",
    "            print(\"Anki sync successful.\")\n",
    "    else:\n",
    "        raise ConnectionError(\"Failed to connect to AnkiConnect for syncing.\")\n",
    "\n",
    "def get_latest_anki_flaschard_words():\n",
    "    flashcard_set = set()\n",
    "\n",
    "    # Step 0: Sync Anki with the cloud\n",
    "    sync_anki()\n",
    "    \n",
    "    # Step 1: Find all card information in the \"Pleco Import\" deck\n",
    "    card_info = get_card_info(\"Pleco Import\")\n",
    "    print(f\"Total cards found in 'Pleco Import': {len(card_info)}\")\n",
    "\n",
    "    # Step 2: Extract the \"Front\" field for each card and add to the set\n",
    "    for card in card_info:\n",
    "        front_field = re.sub(r'[^\\u4e00-\\u9fff]', '', card['fields']['Front']['value'])  # Filter out non-Chinese characters\n",
    "        flashcard_set.add(front_field)\n",
    "    print(\"success\")\n",
    "\n",
    "    return flashcard_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main google drive functions\n",
    "def get_latest_flashcard_xml():\n",
    "    files = get_items_by_name(SERVICE, FLASHCARD_FILE_NAME, is_folder=False, is_root=True)\n",
    "    if len(files) == 0:\n",
    "        print(\"No files found.\")\n",
    "        return None\n",
    "        \n",
    "    # Download the content of the target file\n",
    "    target_file = files[0]\n",
    "    request = SERVICE.files().get_media(fileId=target_file['id'])\n",
    "    file_content = request.execute()\n",
    "    file_text = file_content.decode('utf-8')\n",
    "    modified_time = datetime.datetime.fromisoformat(target_file['modifiedTime'].replace('Z', '+00:00'))\n",
    "    local_time = modified_time.astimezone()\n",
    "    print(\"Latest flashcard xml last modified time:\", local_time.strftime('%Y-%m-%d %H:%M:%S %Z%z'))\n",
    "    return file_text\n",
    "\n",
    "def archive_flashcard_xmls(archive_latest=False):\n",
    "    files = get_items_by_name(SERVICE, FLASHCARD_FILE_NAME, is_folder=False, is_root=True)\n",
    "    if len(files) == 0:\n",
    "        print(\"No files found.\")\n",
    "        return\n",
    "\n",
    "    # move irrelevant files to archive folder\n",
    "    for f in files[0 if archive_latest else 1:]:\n",
    "        move_file_to_folder(SERVICE, f['id'], FLASCHARD_FILE_ARCHIVE_FOLDER_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main flashcard processing functions\n",
    "def convert_pinyin(pinyin):\n",
    "    tone_marks = {\n",
    "        'a': 'āáǎàa',\n",
    "        'e': 'ēéěèe',\n",
    "        'i': 'īíǐìi',\n",
    "        'o': 'ōóǒòo',\n",
    "        'u': 'ūúǔùu',\n",
    "        'ü': 'ǖǘǚǜü'\n",
    "    }\n",
    "    result = []\n",
    "    cleaned_pinyin= re.sub(r'\\s', '', pinyin)\n",
    "\n",
    "    for syllable in re.split(r'(?<=\\d)(?=\\D)', cleaned_pinyin):\n",
    "        if syllable[-1].isdigit():\n",
    "            tone = int(syllable[-1])\n",
    "            syllable = syllable[:-1]\n",
    "            for vowel in 'aeiouü':\n",
    "                if vowel in syllable:\n",
    "                    syllable = syllable.replace(vowel, tone_marks[vowel][tone - 1])\n",
    "                    break\n",
    "        result.append(syllable)\n",
    "    return ' '.join(result)\n",
    "\n",
    "def process_flashcard_xml(xml_text):\n",
    "    \"\"\"returns a list of dictionaries with simplified, traditional, pinyin, definition, and dictid\"\"\"\n",
    "    # example xml text: <?xml version=\"1.0\" encoding=\"UTF-8\"?><plecoflash formatversion=\"2\" creator=\"Pleco User 19097293\" generator=\"Pleco 2.0 Flashcard Exporter\" platform=\"iPhone OS\" created=\"1735693200\"><categories></categories><cards><card language=\"chinese\" created=\"1735513394\" modified=\"1735513394\"><entry><headword charset=\"sc\">游戏</headword><headword charset=\"tc\">遊戲</headword><pron type=\"hypy\" tones=\"numbers\">you2xi4</pron><defn>noun recreation; game 做遊戲 Zuò yóuxì play games verb play 孩子們在公園裡遊戲。 Háizi men zài gōngyuán lǐ yóuxì. The children are playing in the park.</defn></entry><dictref dictid=\"PACE\" entryid=\"35050240\"/></card><card language=\"chinese\" created=\"1735514285\" modified=\"1735514285\"><entry><headword charset=\"sc\">革新</headword><headword charset=\"tc\">革新</headword><pron type=\"hypy\" tones=\"numbers\">ge2xin1</pron><defn>noun innovation; renovation 技術革新 jìshù géxīn technological innovation verb innovate; improve 傳統的手工藝技術不斷革新。 Chuántǒng de shǒu gōngyì jìshù bùduàn géxīn. Traditional handicraft techniques are being steadily improved.</defn></entry><dictref dictid=\"PACE\" entryid=\"21578752\"/></card>\n",
    "\n",
    "    # Parse the XML content\n",
    "    root = ET.fromstring(xml_text)\n",
    "\n",
    "    # Find all <card> tags\n",
    "    cards = root.findall('.//card')\n",
    "\n",
    "    # Extract and print each entry\n",
    "    entries_data = []\n",
    "    problematic_cards = []\n",
    "    for card in cards:\n",
    "        try:\n",
    "            entries = card.findall('entry')\n",
    "            if len(entries) != 1:\n",
    "                print(ET.tostring(card, encoding='unicode'))\n",
    "                raise ValueError(\"Card does not contain exactly one entry.\")\n",
    "            \n",
    "            entry = entries[0]\n",
    "            simplified = entry.find('headword[@charset=\"sc\"]').text\n",
    "            traditional = entry.find('headword[@charset=\"tc\"]').text\n",
    "            pinyin = convert_pinyin(entry.find('pron').text)\n",
    "            if entry.find('defn') is None:\n",
    "                definition = \"\"\n",
    "            else:\n",
    "                definition = entry.find('defn').text\n",
    "            dictid = card.find('dictref').attrib['dictid']\n",
    "            \n",
    "            entry_data = {\n",
    "                'simplified': simplified,\n",
    "                'traditional': traditional,\n",
    "                'pinyin': pinyin,\n",
    "                'definition': definition,\n",
    "                'dictid': dictid,\n",
    "            }\n",
    "            if definition:\n",
    "                entries_data.append(entry_data)\n",
    "            else:\n",
    "                problematic_cards.append(entry_data)\n",
    "        except Exception as e:\n",
    "            print(ET.tostring(card, encoding='unicode'))\n",
    "            raise e\n",
    "\n",
    "    return entries_data, problematic_cards\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_by_name(service, file_name):\n",
    "    \"\"\"List files with a specific name from Google Drive.\"\"\"\n",
    "    try:\n",
    "        results = service.files().list(\n",
    "            q=f\"name = '{file_name}'\",\n",
    "            fields=\"nextPageToken, files(id, name, mimeType, modifiedTime, parents)\",\n",
    "            orderBy=\"modifiedTime desc\"\n",
    "        ).execute()\n",
    "        return results.get('files', [])\n",
    "    except HttpError as error:\n",
    "        print(f\"An error occurred: {error}\")\n",
    "        return []\n",
    "\n",
    "def process_file(file):\n",
    "    \"\"\"Placeholder function to process a file.\"\"\"\n",
    "    print(f\"Processing file: {file['name']} (ID: {file['id']})\")\n",
    "\n",
    "\n",
    "def load_processed_files():\n",
    "    \"\"\"Load the list of processed file IDs from a local memory file.\"\"\"\n",
    "    if os.path.exists(MEMORY_FILE):\n",
    "        with open(MEMORY_FILE, 'r') as file:\n",
    "            return set(json.load(file))\n",
    "    return set()\n",
    "\n",
    "def save_processed_files(processed_files):\n",
    "    \"\"\"Save the list of processed file IDs to a local memory file.\"\"\"\n",
    "    with open(MEMORY_FILE, 'w') as file:\n",
    "        json.dump(list(processed_files), file)\n",
    "\n",
    "def monitor_google_drive(target_folder_id, interval=60):\n",
    "    \"\"\"Periodically check for new files, process them, and move them.\"\"\"\n",
    "    service = authenticate_google_drive()\n",
    "    processed_files = load_processed_files()\n",
    "\n",
    "    while True:\n",
    "        print(\"Checking for new files named 'pleco_flashcards.xml'...\")\n",
    "        files = list_files_by_name(service, \"pleco_flashcards.xml\")\n",
    "\n",
    "        for file in files:\n",
    "            if file['id'] not in processed_files:\n",
    "                # Process the file\n",
    "                process_file(file)\n",
    "\n",
    "                # Move the file to the specified folder\n",
    "                move_file_to_folder(service, file['id'], target_folder_id)\n",
    "\n",
    "                # Mark the file as processed and save to memory\n",
    "                processed_files.add(file['id'])\n",
    "                save_processed_files(processed_files)\n",
    "        \n",
    "        # Wait for the specified interval before checking again\n",
    "        time.sleep(interval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sandbox 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "\n",
    "def convert_unicode_segments(text):\n",
    "    \"\"\"Convert unicode segments (like &#33368;) to the actual unicode character.\"\"\"\n",
    "    return html.unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anki sync successful.\n",
      "Total cards found in 'Pleco Import': 1659\n",
      "success\n",
      "Latest flashcard xml last modified time: 2025-01-02 12:17:32 EST-0500\n",
      "1648 flashcard entries found| 1 error entries found\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    current_anki_flash_card_words = get_latest_anki_flaschard_words()\n",
    "    xml_text = get_latest_flashcard_xml()\n",
    "    flashcard_entries, error_entries = process_flashcard_xml(xml_text)\n",
    "    print(len(flashcard_entries), \"flashcard entries found|\", len(error_entries), \"error entries found\")\n",
    "\n",
    "    anki_cards = get_card_info(\"Pleco Import\")\n",
    "    anki_cards_dict = {re.sub(r'[^\\u4e00-\\u9fff]', '', card['fields']['Front']['value']): card for card in anki_cards}\n",
    "    for entry in flashcard_entries:\n",
    "        entry['formatted_back'] = convert_unicode_segments(anki_cards_dict[entry['traditional']]['fields']['Back']['value'])\n",
    "\n",
    "    with open(\"flashcard_entries.json\", \"w\") as f:\n",
    "        json.dump(flashcard_entries, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
